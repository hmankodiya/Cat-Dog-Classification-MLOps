{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from torch.utils.data import random_split,DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "import gc\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    IMAGE_SIZE   = (224,224)\n",
    "    TRAIN_FOLDER = './cat-dog/training_set/'\n",
    "    TEST_FOLDER  = './cat-dog/test_set/'\n",
    "    DEVICE       = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    SPLIT        = (0.7,0.3)\n",
    "    TRANSFORMS   =  transforms.Compose([transforms.Resize(size=IMAGE_SIZE),\n",
    "                                       transforms.ToTensor()])\n",
    "    BATCH_SIZE   = 5\n",
    "    MODEL_DIR    = 'Pytorch/predefined/'\n",
    "    EPOCH        =  10\n",
    "\n",
    "\n",
    "    torch.hub.set_dir(MODEL_DIR)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTestLoader:\n",
    "    def __init__(self):\n",
    "        \"\"\" DataLoader Class \"\"\"\n",
    "        pass\n",
    "    def get_data(self, data_folder, split_ratio=Config.SPLIT,\n",
    "                 split=True, batch_size=Config.BATCH_SIZE,\n",
    "                 transforms=Config.TRANSFORMS):\n",
    "        if split:\n",
    "            \"\"\" Call method for quick data loading \"\"\"\n",
    "            self.train = ImageFolder(data_folder,transform=transforms)\n",
    "            self.batch_size = batch_size\n",
    "            self.split_ratio = split_ratio\n",
    "            tr,ts = int(len(self.train)*split_ratio[0]),len(self.train)-int(len(self.train)*split_ratio[0])\n",
    "            train_ds,val_ds = random_split(self.train, [tr,ts])\n",
    "            self.train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "            self.val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "            return self.train_loader,self.val_loader\n",
    "        else:\n",
    "            self.test = ImageFolder(data_folder,transform=transforms)\n",
    "            self.test_loader = DataLoader(self.test)\n",
    "            return self.test_loader\n",
    "dl = TrainTestLoader()\n",
    "train_loader,val_loader = dl.get_data(Config.TRAIN_FOLDER)\n",
    "test_loader = dl.get_data(Config.TEST_FOLDER,split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1121, 481)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader),len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Modifying Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in Pytorch/predefined/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "resnet    = torch.hub.load('pytorch/vision:v0.10.0','resnet18', pretrained=False)\n",
    "num_ftrs  = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs,1)\n",
    "resnet    = resnet.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor([1,0])\n",
    "preds  = torch.tensor([0.6,0.1])\n",
    "accuracy = torchmetrics.Accuracy()\n",
    "accuracy(preds, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def score(yhat,y):\n",
    "        \"\"\"Accuracy Score\n",
    "\n",
    "        Args:\n",
    "            yhat (float): probabilities\n",
    "            y (integer(0/1)): class label \n",
    "\n",
    "        Returns:\n",
    "            float: range 0-1\n",
    "        \"\"\"\n",
    "        accuracy = torchmetrics.Accuracy()\n",
    "        return accuracy(yhat,y)\n",
    "    def f1(yhat,y):\n",
    "        \"\"\"F1-Score\n",
    "\n",
    "        Args:\n",
    "            yhat (float): probabilities\n",
    "            y (integer(1/0)): class label\n",
    "\n",
    "        Returns:\n",
    "            float: range 0-1\n",
    "        \"\"\"\n",
    "        f1 = torchmetrics.F1Score()\n",
    "        return f1(yhat,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target  = torch.tensor([0,1])\n",
    "preds = torch.tensor([0.1,0.9])\n",
    "Metrics.score(preds,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attaching Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelFinal(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def make(self, resnet):\n",
    "        self.resnet = resnet\n",
    "    def train(self, X_cuda, y_cuda):\n",
    "        out = self(X_cuda)\n",
    "        return torch.nn.functional.binary_cross_entropy(out, y_cuda)\n",
    "    def fit(self, train_loader, val_loader=None, epochs=1, lr=0.001):\n",
    "        opt = torch.optim.Adam(self.parameters(),lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            total_avg_loss = 0\n",
    "            total_loss = 0\n",
    "            iterator_loader = tqdm.tqdm(train_loader, desc='Train Batch', total=len(train_loader))\n",
    "            for iteration,batch in enumerate(iterator_loader):\n",
    "                X_cuda = batch[0].to(dtype=torch.float32, device=Config.DEVICE)\n",
    "                y_cuda = batch[1].to(dtype=torch.float32, device=Config.DEVICE).unsqueeze(1)\n",
    "                loss = self.train(X_cuda, y_cuda)\n",
    "                total_loss += loss.item()\n",
    "                total_avg_loss = total_loss/(iteration+1)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                torch.cuda.empty_cache()\n",
    "                iterator_loader.set_postfix({'total batch loss':loss.item(), 'total avg loss': total_avg_loss})\n",
    "            print()\n",
    "            self.validate(val_loader)\n",
    "            gc.collect()\n",
    "\n",
    "    def validate(self,val_loader):\n",
    "        average_val_score = 0\n",
    "        average_f1_score = 0\n",
    "        total_f1 = 0\n",
    "        total_score = 0\n",
    "        iterator_loader = tqdm.tqdm(val_loader, desc='Val Batch', total=len(val_loader))\n",
    "        for iteration,batch in enumerate(iterator_loader):\n",
    "            X_val_cuda = batch[0].to(dtype=torch.float32, device=Config.DEVICE)\n",
    "            y_val = torch.unsqueeze(batch[1].to(dtype=torch.int32), dim=1)\n",
    "            predictions  = self.predict(X_val_cuda).to('cpu')\n",
    "            \n",
    "            accuracy = Metrics.score(predictions, y_val)\n",
    "            total_score += accuracy.item()\n",
    "            average_val_score  = total_score/(iteration+1)\n",
    "            \n",
    "            f1 = Metrics.f1(predictions,y_val)\n",
    "            total_f1 += f1.item()\n",
    "            average_f1_score = total_f1/(iteration+1)\n",
    "            \n",
    "            iterator_loader.set_postfix({'average f1 score':average_f1_score, 'average accuracy score': average_val_score})\n",
    "            \n",
    "        return average_val_score, average_f1_score\n",
    "            \n",
    "    def forward(self, X):\n",
    "        model_output = self.resnet(X)\n",
    "        softmax_output = torch.nn.Sigmoid()(model_output)\n",
    "        return softmax_output\n",
    "    def predict(self,X):\n",
    "        with torch.no_grad():\n",
    "            return self(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = torch.tensor([0])\n",
    "int(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itr = tqdm.tqdm([1,2,3,4,5,6,7],desc='hello')\n",
    "# for i,batch in enumerate(itr):\n",
    "#     print(i)\n",
    "#     itr.set_postfix({'i':i})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model_attached\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attached = ModelFinal()\n",
    "model_attached.make(resnet=resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in val_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 224, 224]), torch.Size([5]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(y,dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Batch: 100%|█| 481/481 [00:17<00:00, 27.93it/s, average f1 score=0.513, average accuracy score=0.593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5931393058347108, 0.5129739698526021)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attached.validate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_attached(x.to(dtype=torch.float32,device=Config.DEVICE)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val Batch:   0%|                                                                | 0/481 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The highest label in `target` should be smaller than the size of the `C` dimension of `preds`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000029?line=0'>1</a>\u001b[0m model_attached\u001b[39m.\u001b[39;49mvalidate(val_loader)\n",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 12'\u001b[0m in \u001b[0;36mModelFinal.validate\u001b[0;34m(self, val_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=37'>38</a>\u001b[0m y_val \u001b[39m=\u001b[39m batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint32)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=38'>39</a>\u001b[0m predictions  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(X_val_cuda)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=40'>41</a>\u001b[0m accuracy \u001b[39m=\u001b[39m Metrics\u001b[39m.\u001b[39;49mscore(predictions, y_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=41'>42</a>\u001b[0m total_score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m accuracy\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=42'>43</a>\u001b[0m average_val_score  \u001b[39m=\u001b[39m total_score\u001b[39m/\u001b[39m(iteration\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 9'\u001b[0m in \u001b[0;36mMetrics.score\u001b[0;34m(yhat, y)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=2'>3</a>\u001b[0m \u001b[39m\"\"\"Accuracy Score\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=3'>4</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=4'>5</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=9'>10</a>\u001b[0m \u001b[39m    float: range 0-1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=10'>11</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=11'>12</a>\u001b[0m accuracy \u001b[39m=\u001b[39m torchmetrics\u001b[39m.\u001b[39mAccuracy()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000020?line=12'>13</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy(yhat,y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:237\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_full_state_update(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    236\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_reduce_state_update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    239\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:301\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m  \u001b[39m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[39m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    302\u001b[0m batch_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute()\n\u001b[1;32m    304\u001b[0m \u001b[39m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/metric.py:383\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_grad):\n\u001b[1;32m    382\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m         update(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    384\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    385\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected all tensors to be on\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py:219\u001b[0m, in \u001b[0;36mAccuracy.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m\"\"\"Update state with predictions and targets. See\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39m:ref:`pages/classification:input types` for more information on input\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[39mtypes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m    target: Ground truth labels\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\" returns the mode of the data (binary, multi label, multi class, multi-dim multi class) \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m mode \u001b[39m=\u001b[39m _mode(preds, target, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtop_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticlass, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    222\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m mode\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py:59\u001b[0m, in \u001b[0;36m_mode\u001b[0;34m(preds, target, threshold, top_k, num_classes, multiclass, ignore_index)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mode\u001b[39m(\n\u001b[1;32m     30\u001b[0m     preds: Tensor,\n\u001b[1;32m     31\u001b[0m     target: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     ignore_index: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataType:\n\u001b[1;32m     38\u001b[0m     \u001b[39m\"\"\"Finds the mode of the input tensors.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m        <DataType.MULTICLASS: 'multi-class'>\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     mode \u001b[39m=\u001b[39m _check_classification_inputs(\n\u001b[1;32m     60\u001b[0m         preds,\n\u001b[1;32m     61\u001b[0m         target,\n\u001b[1;32m     62\u001b[0m         threshold\u001b[39m=\u001b[39;49mthreshold,\n\u001b[1;32m     63\u001b[0m         top_k\u001b[39m=\u001b[39;49mtop_k,\n\u001b[1;32m     64\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes,\n\u001b[1;32m     65\u001b[0m         multiclass\u001b[39m=\u001b[39;49mmulticlass,\n\u001b[1;32m     66\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m     67\u001b[0m     )\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m mode\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchmetrics/utilities/checks.py:281\u001b[0m, in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, multiclass, top_k, ignore_index)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou have set `multiclass=False`, but have more than 2 classes in your data,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m based on the C dimension of `preds`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m implied_classes:\n\u001b[0;32m--> 281\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    282\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe highest label in `target` should be smaller than the size of the `C` dimension of `preds`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         )\n\u001b[1;32m    285\u001b[0m \u001b[39m# Check that num_classes is consistent\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mif\u001b[39;00m num_classes:\n",
      "\u001b[0;31mValueError\u001b[0m: The highest label in `target` should be smaller than the size of the `C` dimension of `preds`."
     ]
    }
   ],
   "source": [
    "model_attached.validate(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Batch: 100%|████| 1121/1121 [01:55<00:00,  9.73it/s, total batch loss=0.703, total avg loss=0.677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000009?line=0'>1</a>\u001b[0m model_attached\u001b[39m.\u001b[39;49mfit(train_loader\u001b[39m=\u001b[39;49mtrain_loader,epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 12'\u001b[0m in \u001b[0;36mModelFinal.fit\u001b[0;34m(self, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=24'>25</a>\u001b[0m     iterator_loader\u001b[39m.\u001b[39mset_postfix({\u001b[39m'\u001b[39m\u001b[39mtotal batch loss\u001b[39m\u001b[39m'\u001b[39m:loss\u001b[39m.\u001b[39mitem(), \u001b[39m'\u001b[39m\u001b[39mtotal avg loss\u001b[39m\u001b[39m'\u001b[39m: total_avg_loss})\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate(val_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=27'>28</a>\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n",
      "\u001b[1;32m/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb Cell 12'\u001b[0m in \u001b[0;36mModelFinal.validate\u001b[0;34m(self, val_loader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=32'>33</a>\u001b[0m total_f1 \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=33'>34</a>\u001b[0m total_score \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=34'>35</a>\u001b[0m iterator_loader \u001b[39m=\u001b[39m tqdm\u001b[39m.\u001b[39mtqdm(val_loader, desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mVal Batch\u001b[39m\u001b[39m'\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39;49m(val_loader))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m iteration,batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iterator_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/harsh/DATA/PYTHON/Pytorch/Cat-Dog-PyTorch/model.ipynb#ch0000006?line=36'>37</a>\u001b[0m     X_val_cuda \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39mConfig\u001b[39m.\u001b[39mDEVICE)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "model_attached.fit(train_loader=train_loader,val_loader=val_loader,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in val_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 224, 224])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_attached.predict(x.to(device=Config.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4551],\n",
       "        [0.4991],\n",
       "        [0.4903],\n",
       "        [0.5212],\n",
       "        [0.5168]], device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e269198fab4eb2ea6fe7c886c38b87b334869f0501ab924e1d16d60aeba5d23"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
